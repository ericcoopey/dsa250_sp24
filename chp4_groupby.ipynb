{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create DataFrame:\n",
      "    Courses    Fee Duration  Discount\n",
      "0    Spark  22000   30days    1000.0\n",
      "1  PySpark  25000   50days    2300.0\n",
      "2   Hadoop  23000   55days    1000.0\n",
      "3   Python  24000   40days    1200.0\n",
      "4   Pandas  26000   60days    2500.0\n",
      "5   Hadoop  25000   35days       NaN\n",
      "6    Spark  25000   30days    1400.0\n",
      "7   Python  22000   50days    1600.0\n",
      "8       NA   1500   40days       0.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "technologies   = ({\n",
    "    'Courses':[\"Spark\",\"PySpark\",\"Hadoop\",\"Python\",\"Pandas\",\"Hadoop\",\"Spark\",\"Python\",\"NA\"],\n",
    "    'Fee' :[22000,25000,23000,24000,26000,25000,25000,22000,1500],\n",
    "    'Duration':['30days','50days','55days','40days','60days','35days','30days','50days','40days'],\n",
    "    'Discount':[1000,2300,1000,1200,2500,None,1400,1600,0]\n",
    "          })\n",
    "df = pd.DataFrame(technologies)\n",
    "print(\"Create DataFrame:\\n\", df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As I said above groupby() function returns DataFrameGroupBy object after collecting the identical data into groups from pandas DataFrame. To perform several operations on DataFrameGroupby object using sum(), mean() e.t.c.\n",
    "\n",
    "Let’s apply the groupby() function along with the sum() function to perform the sum operation on grouped data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get sum of grouped data:\n",
      "            Fee      Duration  Discount\n",
      "Courses                               \n",
      "Hadoop   48000  55days35days    1000.0\n",
      "NA        1500        40days       0.0\n",
      "Pandas   26000        60days    2500.0\n",
      "PySpark  25000        50days    2300.0\n",
      "Python   46000  40days50days    2800.0\n",
      "Spark    47000  30days30days    2400.0\n"
     ]
    }
   ],
   "source": [
    "# Use groupby() to compute the sum\n",
    "df2 =df.groupby(['Courses']).sum()\n",
    "print(\"Get sum of grouped data:\\n\", df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the time we would need to perform groupby on multiple columns of DataFrame, you can do this by passing a list of column labels you want to perform groupby on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get sum of groupby multiple columns:\n",
      "                     Fee  Discount\n",
      "Courses Duration                 \n",
      "Hadoop  35days    25000       0.0\n",
      "        55days    23000    1000.0\n",
      "NA      40days     1500       0.0\n",
      "Pandas  60days    26000    2500.0\n",
      "PySpark 50days    25000    2300.0\n",
      "Python  40days    24000    1200.0\n",
      "        50days    22000    1600.0\n",
      "Spark   30days    47000    2400.0\n"
     ]
    }
   ],
   "source": [
    "# Group by multiple columns\n",
    "df2 =df.groupby(['Courses', 'Duration']).sum()\n",
    "print(\"Get sum of groupby multiple columns:\\n\", df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add Index to the grouped data\n",
    "\n",
    "By default groupby() function doesn’t return the row Index, you can add the index using the DataFrame.reset_index() method.\n",
    "\n",
    "Related: You can group the Pandas DataFrame by index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After adding index to DataFrame:\n",
      "    Courses Duration    Fee  Discount\n",
      "0   Hadoop   35days  25000       0.0\n",
      "1   Hadoop   55days  23000    1000.0\n",
      "2       NA   40days   1500       0.0\n",
      "3   Pandas   60days  26000    2500.0\n",
      "4  PySpark   50days  25000    2300.0\n",
      "5   Python   40days  24000    1200.0\n",
      "6   Python   50days  22000    1600.0\n",
      "7    Spark   30days  47000    2400.0\n"
     ]
    }
   ],
   "source": [
    "# Add Row Index to the group by result\n",
    "df2 = df.groupby(['Courses','Duration']).sum().reset_index()\n",
    "print(\"After adding index to DataFrame:\\n\", df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also choose whether to include NA/None/Nan in group keys or not by setting dropna parameter. By default the value of dropna set to True. So, it does not include None/Nan values on the group keys set dropna=False parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Fee      Duration  Discount\n",
      "Courses                               \n",
      "Hadoop   48000  55days35days    1000.0\n",
      "NA        1500        40days       0.0\n",
      "Pandas   26000        60days    2500.0\n",
      "PySpark  25000        50days    2300.0\n",
      "Python   46000  40days50days    2800.0\n",
      "Spark    47000  30days30days    2400.0\n"
     ]
    }
   ],
   "source": [
    "# Drop rows that have None/Nan on group keys\n",
    "df2=df.groupby(by=['Courses'], dropna=False).sum()\n",
    "print(df2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add some sorting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Fee      Duration  Discount\n",
      "Courses                               \n",
      "Python   46000  40days50days    2800.0\n",
      "Pandas   26000        60days    2500.0\n",
      "Spark    47000  30days30days    2400.0\n",
      "PySpark  25000        50days    2300.0\n",
      "Hadoop   48000  55days35days    1000.0\n",
      "NA        1500        40days       0.0\n"
     ]
    }
   ],
   "source": [
    "# Sorting group keys on descending order\n",
    "groupedDF = df.groupby('Courses',sort=False).sum()\n",
    "sortedDF=groupedDF.sort_values('Discount', ascending=False)\n",
    "print(sortedDF)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsa250",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
